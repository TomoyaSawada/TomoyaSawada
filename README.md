## Tomoya Sawada, Ph.D. 
Tomoya Sawada is a Research Scientist/Engineer in Computer Vision at Mitsubishi Electric. He graduated from Yamanashi University, Japan in 2012, and has received M.Sc. and Ph.D. degree from the department of computer science at the Yamanashi University, Japan in 2014 and 2015. His research interests include scene understanding such as object detection/semantic segmentation/object tracking/action recognition, AI assisted user interface, generating the natural scene using GANs/Diffusion model, multimodal learning and domain shift/adaptation/transfer.Â 

<h3 align="left">Languages and Tools:</h3>
<p align="left"> <a href="https://azure.microsoft.com/en-in/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/microsoft_azure/microsoft_azure-icon.svg" alt="azure" width="40" height="40"/> </a> <a href="https://aws.amazon.com/?nc1=h_ls" target="_blank"> <img src="https://www.vectorlogo.zone/logos/amazon_aws/amazon_aws-icon.svg" alt="AWS" width="40" height="40"/> </a> <a href="https://www.cprogramming.com/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/c/c-original.svg" alt="c" width="40" height="40"/> </a> <a href="https://www.w3schools.com/cpp/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/cplusplus/cplusplus-original.svg" alt="cplusplus" width="40" height="40"/> </a> <a href="https://www.docker.com/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original-wordmark.svg" alt="docker" width="40" height="40"/> </a> <a href="https://git-scm.com/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> </a> <a href="https://www.java.com" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/java/java-original.svg" alt="java" width="40" height="40"/> </a> <a href="https://www.linux.org/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" alt="linux" width="40" height="40"/> </a> <a href="https://www.mathworks.com/" target="_blank"> <img src="https://upload.wikimedia.org/wikipedia/commons/2/21/Matlab_Logo.png" alt="matlab" width="40" height="40"/> </a> <a href="https://www.mongodb.com/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mongodb/mongodb-original-wordmark.svg" alt="mongodb" width="40" height="40"/> </a> <a href="https://www.mysql.com/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> <a href="https://opencv.org/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/opencv/opencv-icon.svg" alt="opencv" width="40" height="40"/> </a> <a href="https://www.photoshop.com/en" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/photoshop/photoshop-line.svg" alt="photoshop" width="40" height="40"/> </a> <a href="https://www.python.org" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> <a href="https://pytorch.org/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/pytorch/pytorch-icon.svg" alt="pytorch" width="40" height="40"/> </a> <a href="https://scikit-learn.org/" target="_blank"> <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="scikit_learn" width="40" height="40"/> </a> <a href="https://www.tensorflow.org" target="_blank"> <img src="https://www.vectorlogo.zone/logos/tensorflow/tensorflow-icon.svg" alt="tensorflow" width="40" height="40"/> </a> </p>

### Working Experience  
<details>
<summary>July 2023 - March 2024, Joint Research, The University of Tokyo (Matsuo Laboratory)   
   
Research on Generative AI for Industries, adopting various IoT devices  
Collaborate with: Rei Araki, Takaomi Hasegawa, Tadahiro Shidara, Keichi Yokoyama</summary>

   In this project, we investigates the potential of large language models (LLMs) for optimizing HVAC systems in real-world settings. While prior research has primarily focused on simulated environments, this study bridges the gap by deploying and evaluating an LLM-based control system in an actual office. The system collects real-time environmental data and occupant feedback on thermal comfort. This data, along with historical environmental and feedback information, is used to prompt the generative AI model, which predicts optimal HVAC setpoint temperatures throughout the day. The results demonstrate a significant reduction in power consumption (up to 47.92%, equivalent to 39.48 kWh) and a concurrent improvement in occupant comfort (up to 26.36%) compared to the baseline. Notably, regression analysis confirms that these improvements persist even after accounting for external factors such as outside temperature and occupancy. This study highlights the significant potential of generative AI for optimizing HVAC systems, enhancing both energy efficiency and occupant comfort in real-world scenarios. Future research will explore the scalability of this approach, targeting larger-scale building energy management systems in data centers and industrial facilities.
</details>

<details>
<summary>April 2023 - Principal Researcher, Mitsubishi Electric
   
Business Intelligence Strategic Promotion Dept., DX Innovation Center.  
Managing Executive Office: Hiroshi Sakakibara CDO, Executive Officer: Nobuo Asahi  
MITSUBISHI ELECTRIC CORPORATION, Headquarters.  </summary>  

   I have advanced research on generative AI as an expert in this organization, and have been involved in its practical application in business from planning to implementation. I have also been actively expanding my connections with partner companies to promote its social implementation. 
   Conducted research on cutting-edge technologies, including generative AI, by attending international conferences and publishing hundreds of articles for the general public on community sites. Additionally, I have given multiple presentations at company-wide events with hundreds of attendees. Furthermore, I have contributed to the academic community as a reviewer for international journals. By conducting inquiries with industry analysts such as Gartner, I have provided timely suggestions on AI business strategies to company executives, contributing to their decision-making processes.
</details>

<details>
<summary>April 2021 - March 2023, Researcher/Manager, Mitsubishi Electric

Maisart Co-Innovation Center, Business Innovation & DX Strategy Div.  
Managing Executive Office: Hiroshi Sakakibara CDO, Executive Officer: Tomoki Ichikawa, Takashi Mizuochi, Ph.D  
MITSUBISHI ELECTRIC CORPORATION, Headquarters.  </summary>  

   I have used Amazon's Working Backwards method to develop new business from the customer's point of view. I have also provided consulting services as an AI expert, proposing altorithms to solve vustomer problems and considering the profitability of business. 
</details>

<details>
<summary>October 2018 - October 2021, Joint Research, Massachusetts Institute of Technology(MIT)
   
Research on Generative Adversarial Networks(GAN), Annotation System for Semantic Segmentation  
Collaborate with: Professor Antonio Torralba </summary>

   Generative Adversarial Networks(GANs) have been used to generate images with high resolution. However, the placement and detail of the individual parts were not natural. In this project, we developed a method based on the SPADE network to generate images with natural object placement and detail granularity. To overcome the limitations of GANs in generating detailed edges, a method was developed that utilizes CG as a base to clarify boundaries and applies real-world reconstructed textures to achieve high-resolution generated images.
   We investigated the effectiveness of GAN-based reconstruction methods for object generation by applying a method developed by MIT to the CityScape dataset. The generated objects were then used to train the state-of-the-art object detection method DetectoRS. We also evaluated the extent to which real-world data could be reduced without compromising accuracy by varying the proportion of real images in the training dataset. Results showed that reducing the proportion of real images by 50% led to a decrease in mAP (mean Average Precision) of only about 4%, demonstrating the potential of GAN-based data augmentation for reducing the need for large amounts of real-world data in object detection tasks.
   We also developed a tool for automatic annotation to enable a smooth transition from data aquisition to learning.
</details>

<details>
<summary>May,December 2019, Visiting Researcher, Mitsubishi Electric Research Laboratory(MERL)   
   
Research on Object Detection/Segmentation, Face Recognition and Video Anomaly Detection  
Advisors: Michael Jones, Tim Marks, Anoop Cherian, Teng-yok Lee and Alan Sullivan  </summary>

   In this project, I developed a variety of computer vision technologies: 
   - **Object Detection**: I developed an object detection system for the Camera Monitoring System(CMS) of car manufacturing products. This system uses deep learning to identify vehicles and other objects around the car using a camera mounted in the rearview mirrors.
   - **Semantic Segmentation**: I developed a system for automatically extracting people from video footage captured by surveillance cameras. This system uses a combination of computer vision techniques like background subtraction and deep learning to segment people from other objects in the scene.
   - **Face recognition**:  I developed a face recognition system that can identif people from high/low-angle images, such as those captured by surveillance cameras. This system was trained on a large dataset of human faces, and it can accurately identify people even in challenging conditions like poor lightining and occulusion.
   - **Anomalous behavior detections**: I developed a system for detecting anomalous behavior in video footage. This system uses a deep learning-based model to learn the patterns of normal behavior and identify any deviations from these patterns.
</details>

<details>
<summary>October 2017 - October 2018, Joint Research, FreshlyGround Pte Ltd.  
   
Research on Design Thinking, Business Incubation  
Collaborate with: Thierry DO, Shang LIM  </summary>

   In this project, we proposed a system that improves the quality of customer service in Singaporean hotels by using wearable devices such as camera-equipped smart glasses. The system performs real-time facial recognition to identify customers and displays their information on the display of the smart glasses. 
   We developed a prototype and demonstrated its value to several hotel operators. We also learned how to create customer value by applying Design Thinking method.
</details>   

<details>
<summary>October 2016 - October 2018, Joint Research, University of Southern California(USC)  
   
Research on Graph Signal Processing  
Collaborate with: Professor Antonio Ortegaã€€</summary>

   Graph Signal Processing(GSP) is a mathematical technique for processing signals defined on networks(graphs). Conventional sigal processing deals with signals with regular structures such s time and space, while graph signal processing deals with signals with non-structures such as social networks and transportation networks.
   We applied this technology to manufactring and successfully developed a system that automatically classifies videos of human assembly movements into individual work steps. The system uses a graph that represents the bones of the human hand and can also be used to detect abnormalities in assembly work.
</details>

<details>
<summary>April 2015 - March 2021, Research Scientist/Engineer, Mitsubishi Electric  
   
Image Analytics and Processing Technology Group,  
Smart Information Processing Technology Dept.  
INFORMATION TECHNOLOGY R&D CENTER  </summary>
   
   I developed a variety of computer vision technologies: 
   - **Training Data Minimization**: A state-of-the-art object detector was implemented and evaluated using a dataset of approximately 30,000 infrared images for person tracking. The object detector was trained using only RGB images and applied inference after converting the appearance of infrared images to RGB. The proposed method achieved an average precision of 83.3% and an average detection success rate of 63.3%, demonstrating high-accuracy person tracking.
   - **Knowledge Graph Visualization**: We applied Scene Graph, which describes the relationships between objects in a video, to production site footage to extract the tacit knowledge and experience-based actions of workers. In addition, we developed an attention mechanism that inputs the spatial position of objects in the channel direction as a teacher signal and confirmed that it can recognize objects with higher accuracy than the latest object recognition technology.
   - **Online Learning**: We developed a prototype system that can automatically extract learning targets from customer-accumulated information, enabling continuous improvement of AI recognition accuracy over time. We also identified the issue of low performance when not retraining on inference-side data for the Semantic Segmentation task. By adopting online learning and using background subtraction to generate and refine masks, they demonstrated the ability to perform high-precision inference without inference-side training data.
   - **Object Detection**: Small objects are difficult to detect due to the limited amount of information they contain in images. Additionally, in some datasets, small objects are often not annotated, leading to poor learning efficiency. To address these challenges, we developed a mechanism using attention to efficiently collect and acquire information from small objects and integrated it into an object detection system. The system was intended for integration into an electronic mirror (camera monitoring system) as a vehicle-mounted device.
   - **Driving Warning System**: This project aimed to develop an intelligent alert system that combines CMS (camera monitoring system) object recognition technology to assess surrounding vehicle risks with DMS (driver monitoring system) driver information to optimize alert methods, notification content, and notification timing for each driver. The system integrates camera-based sensing of driver information and external risks with AI technology to create an intelligent alert system that adjusts notification levels based on driver awareness.
   - **AI on device system**: A prototype system was developed to perform real-time object recognition on electronic mirror images and display the recognition results on the electronic mirror display. The demo system was showcased at CES2020 to introduce the company's AI technology to car manufacturers and enhance its presence in the industry. The system achieved an average recognition rate of 88.8% under various weather conditions.
   - **Optimizer**: We proposed a novel general-purpose optimizer and demonstrated its effectiveness through preliminary experiments on an object recognition dataset that was previously difficult to converge using conventional methods. The proposed method automatically adjusts the learning rate, enabling the optimizer to focus on learning rare and important information more effectively. Additionally, the method prevents overfitting during the initial training phase by stabilizing the gradient field.
   - **Attentive Notifications for Drivers**: This project involved integrating the company's proprietary object detection technology into a prototype vehicle. The real-time object recognition technology was applied to an ultra-wide-angle 360Â° camera to detect objects in the vehicle's blind spots and alert the driver. The system linked the object recognition results from the external camera with driver information obtained from the DMS (Driver Monitoring System) for notification. The technology was announced in a press release.
   - **Optical Character Recognition**: We developed AI technology that was applied to OCR and symbol recognition, and advanced image processing was used to improve detection and recognition rates. In response to a request for the introduction of a conversion system in the second half of the year, a system was built and provided that automates part of the conversion process using AI processing and allows users to perform conversion processing using a GUI tool. A paper symbol recognition technology using deep learning was developed and achieved a recognition rate of 98%. For OCR technology, fine-tuning was also performed and a recognition rate of 99% was achieved.
   - **Document Alignment**: In this project, I developed and deployed an automated financial document position correction system. The software takes as input a set of images captured or scanned by a camera and projects the positions of all images onto the appearance of a front-facing shot. After the software was provided, a new challenge of improving speed was identified, and the system was incorporated into a simple system that estimates an external rectangle.
   - **Action Recognition**: We were engaged in collaborative research with Takenaka Corporation and serves as the technical representative for Takenaka Technical Research Institute's open technology demonstrations. They have developed a system that utilizes sensors to identify and visualize human active behaviors (affirmation, negation, and smiling) using HoloLens.
   - **Anomaly Detection**: I evaluated a Deep Learning-based person detection method using data from surveillance cameras on actual railway vehicles and conducted a feasibility study. I also developed a low-compute method for crowd analysis and participated in meetings with railway operators to discuss the feasibility of using Deep Learning. In addition, I constructed an algorithm for detecting suspicious objects in station premises and vehicles and developed a system with visualizing pedestrian.
</details>

### Professional Activities
- The Visual Computer, International Journal of Computer Graphics(2020-2023)
- Consumer Device & System(CDS) Transaction, Information Processing Society of Japan(2020)

### Education
1. Registered Scrum Master, Having Completed Scrum Inc.'s Registered Scrum Master Training, and having passed the credentialing exam, 2023. 
2. CEFR C1 (Advanced Level), Completed a 272 lesson program, St Giles International Language Centres(Canada) Ltd., 2020.
3. Ph.D in Computer Science(GPA 3.8), University of Yamanashi, 2015.  
'Sequential Images Summarization based on Viewer's Interests and Aesthetic Composition'  
(Advisor: Professor Xiaoyang Mao, Associate Professor Masahiro Toyoura)
4. M.S. in Computer Science(GPA 3.6), University of Yamanashi, 2014.  
'Film Comic Generation based on Viewer's Interests and Aesthetic Composition' (Best Presentation Award)  
(Advisor: Professor Xiaoyang Mao, Associate Professor Masahiro Toyoura)
5. B.S. in Engineering, University of Yamanashi, 2012.  
'Automatic Film Comic Generation with Eye-tracking data' (Best Presentation Award)  
(Advisor: Professor Xiaoyang Mao, Associate Professor Masahiro Toyoura) 

### Awards  
- Director of Export Control Yoshifumi Sakamoto Award, T.Sawada(2022, June) 'Realization of data handling with risk minimization in overseas cloud for data linkage and data-driven business', Mitsubishi Electric Corporation. 
- CTO Masahiro Fujita Award, T.Sawada(2018, March) 'Development and Expansion of Maisart Technology', Mitsubishi Electric Corporation. 
- Information Technology R&D Center GM Tetsuo Nakagawaji Award, T.Sawada(2017, March) 'Fundamental Technology Development of Self-driving Vehicle(Level3)', Mitsubishi Electric Corporation. 
- Best Student Award, T.Sawada (2014, March), Integrated Graduate School of Medicine and Engineering, University of Yamanashi.
- Scholarship Full Exemption  
T.Sawada (2014, March), Repayment Exemption for Students with Excellent Grades -FY2014-, Japan Student Services Organization (JASSO) Scholarship) 
- Best Student Award, T.Sawada (2012, March), Faculty of Engineering, University of Yamanashi. 
- Best Poster Award  
T.Sawada, M.Toyoura, X.Mao (2012, March) 'Using Eye-tracking Data for Automatic Film Comic Generation', Forum on Art and Science. 

### Journal Articles
- T.Sawada,  Y.Goto,  M.Toyoura,  X.Mao,  J.Gyoba (2015, June) 'Saliency Map for Images with Leading Lines', The Journal of the Institute of Electronics, Information and Communication Engineers, Vol.J98â€A,  No.6, pp.446â€449.  
- T.Sawada, M.Toyoura, X.Mao (2013, September) 'Automatic Film Comic Generation Using iMap', The Journal of the Institute of Image Electronics Engineers of Japan, Vol. 42, No. 5, pp. 671â€680.
- T.Sawada, M.Toyoura, X.Mao (2012, March) 'Automatic Creation of Film Comic Using Eye-Tracking Data', The Technical Letter of the Institute of Image Information and Television Engineers, Vol. 36, No.16, pp. 153-156. 

### International Conference (Refereed)
- T. Sawada, H. Hasegawa, K. Yokoyama, M. Mizuno,"Office-in-the-Loop for Building HVAC Control with Multimodal Foundation Models," 2024 The 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation (BuildSys 2024), November, 2024, Hangzhou, China, pp.110-120, doi: 10.1145/3671127.3698182.
- T. Sawada and M. Nakamura, "INTELLIGENT WARNING SYSTEM MONITORING VEHICLE SURROUNDING AND DRIVER'S BEHAVIOR," 2022 IEEE International Conference on Multimedia and Expo Workshops (ICMEW), July, 2022, Taipei City, Taiwan, pp. 1-4, doi: 10.1109/ICMEW56448.2022.9859326.
- T. Sawada, T. -Y. Lee and M. Mizuno, "VIDEO OBJECT SEGMENTATION WITH ONLINE MASK REFINEMENT," 2022 IEEE International Conference on Multimedia and Expo Workshops (ICMEW), July, 2022, Taipei City, Taiwan, pp. 1-4, doi: 10.1109/ICMEW56448.2022.9859386.
- T. Sawada, T. -Y. Lee and M. Mizuno, "Bottom-Up Saliency Meets Top-Down Semantics For Object Detection," 2021 IEEE International Conference on Image Processing (ICIP), 2021, pp. 729-733, doi: 10.1109/ICIP42928.2021.9506475.
- P. Das, J. Kao, A. Ortega, T. Sawada, H. Mansour, A. Vetro, A. Minezawa (2019, May) 'Hand Graph Representations for Unsupervised Segmentation of Complex Activities', International Conference on Acoustics, Speech, and Signal Processing(ICCASP), pp.4075-4079.
- T. Sawada, M. Toyoura, X. Mao (2017, June) 'Autoâ€Framing Based on User Camera Movement', Computer Graphics International(CGI), pp. 1â€6 (Article 18). 
- K. Fujimori, S. Zhu, T. Sawada, M. Toyoura, X. Mao (2014, November) 'Image based Kansei-words Labeling by Game', NICOGRAPH, pp.81-86.
- T. Sawada, M. Toyoura, X. Mao (2013, January) 'Film Comic Generation with Eye Tracking', International Conference on MultiMedia Modeling (MMM,  Lecture Notes in Computer Science), Vol.7732/2013, pp.467â€478. 
- M. Toyoura, T. Sawada, M. Kunihiro, X. Mao (2012, March) 'Using Eyeâ€Tracking Data for Automatic Film Comic Creation', ACM Simposium on Eye Tracking Research & Applications(ETRA), pp. 373â€376.

### Exhibition and Publication
- Dataiku Community Event (presentation), 'Let's ideate the future of manufacturing powered by generative AI!', Tomoya Sawada, October 2024. <https://techplay.jp/event/957075?utm_source=notifyApplicant&utm_medium=email&utm_campaign=tp_20241016>
- Dataiku Everyday AI Tokyo (presentation), 'Democratizing Generative AI with AI Platforms: Harnessing the Power and Potential of Multimodal Generative AI', Tomoya Sawada, July 2024.
  - <https://events.dataiku.com/everyday-ai-summit-tokyo>
  - <https://news.mynavi.jp/techplus/article/20240725-2992336/>
  - <https://www.youtube.com/watch?v=bEvo_NDrQgY>
- SORACOM Discovery (presentation), 'Mitsubishi Electric's Foray into Generative AI for Manufacturing: Applications and Case Studies', Tomoya Sawada, Keiichi Yokoyama, Yuta Imai, July 2024.
  - <https://discovery.soracom.jp/2024/session/detail/sd006.html>
  - <https://dcross.impress.co.jp/docs/talk/003728.html>
  - <https://ascii.jp/elem/000/004/217/4217392/>
- News Release, 'Mitsubishi Electric, Soracom, and Matsuo Institute's "IoT Ã— GenAI Lab" Conduct Proof-of-Concept Experiment on Air Conditioner Control Using IoT and Generative AI', SORACOM Inc., July 2024. <https://soracom.com/ja/news/20240711-iot-genai-poc-report>
- Qiita, 'CVPR2024 Paper Introduction', Tomoya Sawada, June 2024. <https://qiita.com/tags/cvpr2024>
- Qiita, 'NeurIPS2023 Paper Introduction', Tomoya Sawada, December 2023. <https://qiita.com/tags/neurips2023>
- Qiita, 'ICCV2023 Paper Introduction', Tomoya Sawada, October 2023. <https://qiita.com/tags/iccv2023>
- Qiita, 'CVPR2023 Paper Introduction', Tomoya Sawada, June 2023. <https://qiita.com/tags/cvpr2023>
- Intel Corporation Technical Paper, 'Introducing the latest research and development using the OpenVINOâ„¢ toolkit to seamlessly leverage deep learning from edge to cloud', Tomoya Sawada, March 2023. <https://www.intel.co.jp/content/www/jp/ja/internet-of-things/openvino/openvino-methodology-seamlessly-leveraging-dl-e2c.html>
- The Institute of Image Information and Television Engineers, 'Go beyond Artificial Intelligence, towards Augmented Intelligence', Tomoya Sawada, Vol.76, No.4, pp. 485-488, 2022. <https://www.ite.or.jp/contents/kirari/2207kirari.pdf>
- MITSUBISHI ELECTRIC Technical Report, 'Expanding Digital Transformation Creates Customer Value Utilizing AI Technology 'Maisart'', Tomoya Sawada, Keisuke Watanabe, Vol.96, No.2, pp.10-13, 2022. <https://www.giho.mitsubishielectric.co.jp/giho/pdf/2022/2202103.pdf>
- CES, 'Realtime Object Detection for Camera-Monitoring-System', Tomoya Sawada, Masahiro Mizuno, January 2020.
- News Release, 'Mitsubishi Electric Develops Attentive Notification for Drivers', 2019. <https://www.mitsubishielectric.co.jp/news/2019/0122-c.html>
- News Release, 'Mitsubishi Electric Develops Compact-GAN', 2019. <https://www.mitsubishielectric.co.jp/news/2019/pdf/0131.pdf>
- Advanced Technology Expo., 'Object Recognition for Vehicles', Tomoya Sawada, June 2018.
- General Meeting of Shareholders (Mitsubishi Electric), 'Technical Introduction of AI: Object Detection', Tomoya Sawada, May 2018.
- Combined Exhibition of Advanced Technologies(CEATEC), 'Object Detection for Camera-Monitoring-System', Tomoya Sawada, Kazuyuki Miyazawa, March 2018.
- IEEE SPECTRUM, 'AI-Aided Cameras Mean No More Car Mirrors, No More Blind Spots', 2018. <https://spectrum.ieee.org/mitsubishi-electric-develops-highperformance-aibased-mirrorless-car-technology>
- News Release, 'Mitsubishi Electric Develops Object-recognition Camera Technology Using Proprietary AI for Coming Mirrorless Cars', 2018. <http://www.mitsubishielectric.co.jp/news/2018/pdf/0117.pdf>

### Patents
(Domestic Application)
- "è³‡æ–™ç”Ÿæˆè£…ç½®ã€è³‡æ–™ç”Ÿæˆæ–¹æ³•ã€ãŠã‚ˆã³ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2024/009477.
- "äººæãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã€äººæãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ–¹æ³•ã€äººæãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è£…ç½®ã€ãŠã‚ˆã³äººæãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2023/030235. 
- "äººæå…¥æœ­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ã€äººæå…¥æœ­æ”¯æ´æ–¹æ³•ã€äººæå…¥æœ­æ”¯æ´è£…ç½®ã€ãŠã‚ˆã³äººæå…¥æœ­æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2023/030251.
- "å­¦ç¿’è£…ç½®"ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€ç™»éŒ²ç•ªå· 07274071.
- "é…ç­‹æ¤œæŸ»è£…ç½®ã€å­¦ç¿’è£…ç½®ã€é…ç­‹æ¤œæŸ»ã‚·ã‚¹ãƒ†ãƒ åŠã³ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€å®®æœ¬å¥ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2022/039215.
- "æ¨è«–è£…ç½®ã€æ¨è«–æ–¹æ³•åŠã³æ¨è«–ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2022/029598ã€ç™»éŒ²ç•ªå· 07345680. 
- "æ¨è«–è£…ç½®ã€æ¨è«–æ–¹æ³•åŠã³æ¨è«–ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ï¼ˆä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾ï¼‰ã€å‡ºé¡˜ç•ªå· PCT/JP2022/029597ã€ç™»éŒ²ç•ªå· 07317246. ã€€
- "å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã€å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ç”Ÿæˆæ–¹æ³•ã€æƒ…å ±å‡¦ç†è£…ç½®ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã€ãŠã‚ˆã³æ¨å®šè£…ç½®"ã€æ¾¤ç”°å‹å“‰ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å‡ºé¡˜ç•ªå·ã€€PCT/JP2021/044400ã€ç™»éŒ²ç•ªå· 07413528.
- "é‹è»¢æ”¯æ´åˆ¶å¾¡è£…ç½®åŠã³é‹è»¢æ”¯æ´åˆ¶å¾¡æ–¹æ³•"ã€æ¾¤ç”°å‹å“‰ ã€ç¦åœ°è³¢ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€ç™»éŒ²ç•ªå·ã€€6932269. 
- "æ¨è«–è£…ç½®ã€æ¨è«–æ–¹æ³•ã€å­¦ç¿’è£…ç½®ã€å­¦ç¿’æ–¹æ³•ã€åŠã³ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€æ¾¤ç”°å‹å“‰ã€ç¦åœ°è³¢ã€å®ˆå±‹èŠ³ç¾ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å‡ºé¡˜ç•ªå·ã€€PCT/JP2021/013407.
- "ç‰©ä½“æ¤œå‡ºè£…ç½®ã€ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è£…ç½®ã€å­¦ç¿’è£…ç½®ã€åŠã³ã€ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆæ–¹æ³•"ã€æ¾¤ç”°å‹å“‰ã€ç¦åœ°è³¢ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å‡ºé¡˜ç•ªå·ã€€PCT/JP2020/048617ã€ç™»éŒ²ç•ªå· 07031081.
- "ãƒ©ãƒ™ãƒªãƒ³ã‚°è£…ç½®åŠã³å­¦ç¿’è£…ç½®"ã€æ¾¤ç”°å‹å“‰ã€ç¦åœ°è³¢ã€å®ˆå±‹èŠ³ç¾ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å‡ºé¡˜ç•ªå·ã€€PCT/JP2020/009092ã€ç™»éŒ²ç•ªå· 07055259.
- "ç‰©ä½“æ¤œå‡ºè£…ç½®ã€ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è£…ç½®åŠã³å­¦ç¿’è£…ç½®"ã€æ¾¤ç”°å‹å“‰ã€ç¦åœ°è³¢ã€å®ˆå±‹èŠ³ç¾ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå· WO2021-130881ã€ç™»éŒ²ç•ªå· 07361949.
- "å¯¾è©±æ”¯æ´è£…ç½®ã€å¯¾è©±æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ã€åŠã³å¯¾è©±æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ "ã€é»’æœ¨å‹è£• ã€é«˜æ©‹å¹¹é›„ ã€é«˜äº•å‹‡å¿— ã€å¤§å¡šè²´å¼˜ ã€å†…å‡ºéš¼äºº ã€æ¾¤ç”°å‹å“‰ ã€å·å³¶å•“å¾ ã€æ´¥ç”°ç”±ä½³ ã€å¿—ç”°å“²éƒ ã€å‰ç”°è«’ ã€çŸ³å·ç¾ç©‚ ã€é£¯ç”°éš†ç¾©ã€(æ ªå¼ä¼šç¤¾ç«¹ä¸­å·¥å‹™åº—ã€ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå· 2020-173714ã€ç™»éŒ²ç•ªå· 07323098   . 
- "ç‰©ä½“æ¤œå‡ºè£…ç½®ãŠã‚ˆã³ç‰©ä½“æ¤œå‡ºæ–¹æ³•"ã€æ¾¤ç”°å‹å“‰ ã€ä¸‰å¶‹è‹±ä¿Š ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å®®æ¾¤ä¸€ä¹‹ ã€å³¯æ¾¤å½° ã€æ—¥é‡ç™¾ä»£ ã€ç‹å¤¢é›„ ã€æ¾è°·ç›´å¤§ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå· WO2018-051459. 
- "äº‹æ•…æƒ…å ±åé›†ã‚·ã‚¹ãƒ†ãƒ ãŠã‚ˆã³äº‹æ•…æƒ…å ±åé›†æ–¹æ³•"ã€å®®æ¾¤ä¸€ä¹‹ ã€é–¢å£ä¿Šä¸€ ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å³¯æ¾¤å½° ã€æœéƒ¨äº®å² ã€æ—¥é‡ç™¾ä»£ ã€æ¾¤ç”°å‹å“‰ ã€æ¾è°·ç›´å¤§ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€	å…¬é–‹ç•ªå· WO2018-008122.
- "ã‚µãƒ¼ãƒè£…ç½®ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åŠã³ã‚»ãƒ³ã‚µæ©Ÿå™¨"ã€å³¯æ¾¤å½° ã€å®®æ¾¤ä¸€ä¹‹ ã€æœéƒ¨äº®å² ã€æ—¥é‡ç™¾ä»£ ã€æ¾¤ç”°å‹å“‰ ã€å®ˆå±‹èŠ³ç¾ ã€é–¢å£ä¿Šä¸€ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå· 2018-061110. 
- "ç‰©ä½“æ¤œå‡ºè£…ç½®åŠã³ç‰©ä½“æ¤œå‡ºæ–¹æ³•"ã€å®®æ¾¤ä¸€ä¹‹ ã€é–¢å£ä¿Šä¸€ ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å³¯æ¾¤å½° ã€æœéƒ¨äº®å² ã€é•·ç€¬ç™¾ä»£ ã€æ¾¤ç”°å‹å“‰ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå· WO2017-094140. 
- "ç”»åƒç‰¹å¾´è¨˜è¿°å­ç¬¦å·åŒ–è£…ç½®ã€ç”»åƒç‰¹å¾´è¨˜è¿°å­å¾©å·è£…ç½®ã€ç”»åƒç‰¹å¾´è¨˜è¿°å­ç¬¦å·åŒ–æ–¹æ³•åŠã³ç”»åƒç‰¹å¾´è¨˜è¿°å­å¾©å·æ–¹æ³•"ã€	å³¯æ¾¤å½° ã€å®ˆå±‹èŠ³ç¾ ã€é–¢å£ä¿Šä¸€ ã€æœéƒ¨äº®å² ã€å®®æ¾¤ä¸€ä¹‹ ã€æ¾¤ç”°å‹å“‰ ã€æ¾è°·ç›´å¤§ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å…¬é–‹ç•ªå·	2017-143425. 
- "æ˜ åƒåé›†ã‚·ã‚¹ãƒ†ãƒ "ã€å®®æ¾¤ä¸€ä¹‹ ã€é–¢å£ä¿Šä¸€ ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å³¯æ¾¤å½° ã€æœéƒ¨äº®å² ã€æ—¥é‡ç™¾ä»£ ã€æ¾¤ç”°å‹å“‰ ã€æ¾è°·ç›´å¤§ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€ç™»éŒ²ç•ªå·ã€€06104482.
- "ç§»å‹•ä½“æ¤œå‡ºè£…ç½®ãŠã‚ˆã³ãã®æ–¹æ³•"ã€æ¾¤ç”°å‹å“‰ã€ä¸‰å¶‹è‹±ä¿Š ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å®®æ¾¤ä¸€ä¹‹ ã€å³¯æ¾¤å½° ã€æ—¥é‡ç™¾ä»£ ã€ç‹å¤¢é›„ ã€æ¾è°·ç›´å¤§ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€ç™»éŒ²ç•ªå·ã€€06230751.
- "æ˜ åƒå‡¦ç†è£…ç½®ãŠã‚ˆã³æ–¹æ³•"ã€å®®æ¾¤ä¸€ä¹‹ ã€é–¢å£ä¿Šä¸€ ã€å‰åŸç§€æ˜ ã€å®ˆå±‹èŠ³ç¾ ã€å³¯æ¾¤å½° ã€æœéƒ¨äº®å² ã€é•·ç€¬ç™¾ä»£ ã€æ¾¤ç”°å‹å“‰ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€ç™»éŒ²ç•ªå·ã€€06116765.
- "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ã€ãƒãƒ¼ãƒ‰è£…ç½®ç¾¤ã€ã‚»ãƒ³ã‚µæ©Ÿå™¨ç¾¤ã€ã‚µãƒ¼ãƒè£…ç½®ç¾¤ãŠã‚ˆã³ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿é€å—ä¿¡æ–¹æ³•"ã€å³¯æ¾¤å½° ã€å®®æ¾¤ä¸€ä¹‹ ã€æœéƒ¨äº®å² ã€é•·ç€¬ç™¾ä»£ã€æ¾¤ç”°å‹å“‰ã€å®ˆå±‹èŠ³ç¾ ã€é–¢å£ä¿Šä¸€ ã€(ä¸‰è±é›»æ©Ÿæ ªå¼ä¼šç¤¾)ã€å‡ºé¡˜ç•ªå·ã€€2016196292.

--

(PCT Application)
- "TRAINED MODEL GENERATION SYSTEM, TRAINED MODEL GENERATION METHOD, INFORMATION PROCESSING DEVICE, NON-TRANSITORY COMPUTER-READABLE STORAGE MEDIUM, TRAINED MODEL, AND ESTIMATION DEVICE", Tomoya SAWADA, (MITSUBISHI ELECTRIC CORPORATION), 20240249178
- "LEARNING DEVICE", Tomoya SAWADA, (MITSUBISHI ELECTRIC CORPORATION), Publication number: 20230394807 
- "Inference device, inference method, and non-transitory computer-readable medium", Tomoya SAWADA, (MITSUBISHI ELECTRIC CORPORATION), 62023078099.6, 20240362901 
- "Inference device, inference method, and non-transitory computer-readable medium", Tomoya SAWADA, (MITSUBISHI ELECTRIC CORPORATION), CA3193358A1.,  20240046512 
- "Dispositif d'Ã©tiquetage et dispositif d'apprentissage", Tomoya SAWADA, Ken FUKUCHI, Yoshimi MORIYA, (MITSUBISHI ELECTRIC CORPORATION), EP4099263A4.
- "LABELING DEVICE AND LEARNING DEVICE", Tomoya SAWADA, Ken FUKUCHI, Yoshimi MORIYA, (MITSUBISHI ELECTRIC CORPORATION), Publication number: 20220366676. 
- "OBJECT DETECTION DEVICE, MONITORING DEVICE, TRAINING DEVICE, AND MODEL GENERATION METHOD", Tomoya SAWADA, Ken FUKUCHI, (MITSUBISHI ELECTRIC CORPORATION), Publication number: 20230410532
- "OBJECT DETECTION DEVICE, MONITORING DEVICE, AND LEARNING DEVICE", Tomoya SAWADA, Ken FUKUCHI, Yoshimi MORIYA, (MITSUBISHI ELECTRIC CORPORATION), Publication number: WO/2021/130881.
- "ACCIDENT INFORMATION COLLECTION SYSTEM, AND ACCIDENT INFORMATION COLLECTION METHOD", Kazuyuki MIYAZAWA, Shunichi SEKIGUCHI, Hideaki MAEHARA, Yoshimi MORIYA, Akira MINEZAWA, Ryoji HATTORI, Momoyo HINO, Tomoya SAWADA, Naohiro SHIBUYA, (MITSUBISHI ELECTRIC CORPORATION), Publication number: 20190193659. 
- "Object detection device and object detection method", Tomoya Sawada, Hidetoshi Mishima, Hideaki Maehara, Yoshimi Moriya, Kazuyuki Miyazawa, Akira Minezawa, Momoyo Hino, Mengxiong Wang, Naohiro Shibuya, (MITSUBISHI ELECTRIC CORPORATION), Patent number: 10943141. 
- "Object detection device and object detection method", Kazuyuki Miyazawa, Shunichi Sekiguchi, Hideaki Maehara, Yoshimi Moriya, Akira Minezawa, Ryoji Hattori, Momoyo Nagase, Tomoya Sawada, (MITSUBISHI ELECTRIC CORPORATION), Patent number: 10643338. 

### Domestic Conferece
- ä¸­æ‘å…‰è²´ï¼Œæ¾¤ç”° å‹å“‰ï¼Œæ‰æœ¬å’Œå¤«ï¼Œâ€œæ™‚ç³»åˆ—å·®åˆ†æƒ…å ±ã‚’ä»˜ä¸ã—ãŸè»½é‡ãªç‰©ä½“èªè­˜æ‰‹æ³•â€ï¼Œç”»åƒç¬¦å·åŒ–ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ãƒ»æ˜ åƒãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ (PCSJ/IMPS)ï¼ŒVol.34ï¼Œpp.84-85ï¼Œ2019-11.
- æ¹§å·ç¿”å¤ªï¼Œæ¾¤ç”°å‹å“‰ï¼Œâ€œç‰©ä½“èªè­˜ç²¾åº¦ã«å¯¾ã™ã‚‹ç”»åƒå“è³ªã®å½±éŸ¿èª¿æŸ»â€ï¼Œç”»åƒç¬¦å·åŒ–ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ãƒ»æ˜ åƒãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ (PCSJ/IMPS)ï¼ŒVol.34ï¼Œ2019-11.
- å®®æ¾¤ä¸€ä¹‹ï¼Œæ¾¤ç”° å‹å“‰ï¼Œé–¢å£ä¿Šä¸€ï¼Œâ€œè»Šè¼‰ã‚«ãƒ¡ãƒ©ã«ã‚ˆã‚‹å¾Œå´æ–¹æ˜ åƒç›£è¦–ã®ãŸã‚ã®ç§»å‹•ç‰©ä½“æ¤œå‡ºâ€ï¼ŒVision Engineering Workshop(ViEW), 2015-12.
- æ¾¤ç”° å‹å“‰ï¼Œè±Šæµ¦ æ­£åºƒï¼ŒèŒ… æšé™½ï¼Œâ€œã‚«ãƒ¡ãƒ©ç§»å‹•ã«åŸºã¥ãã‚ªãƒ¼ãƒˆãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°ã®å®Ÿç¾â€ï¼ŒVisual Computing/ã‚°ãƒ©ãƒ•ã‚£ã‚¯ã‚¹ã¨CADåˆåŒã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼ŒArticle 5ï¼Œ2015-6ï¼
- å¾Œè—¤ æ‚ æ±°ï¼Œæ¾¤ç”° å‹å“‰ï¼Œè±Šæµ¦ æ­£åºƒï¼ŒèŒ… æšé™½ï¼Œè¡Œå ´ æ¬¡æœ—ï¼Œâ€œãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ©ã‚¤ãƒ³ã‚’è€ƒæ…®ã—ãŸé¡•è‘—æ€§ãƒãƒƒãƒ—ã®ä½œæˆâ€ï¼ŒVisual Computing/ã‚°ãƒ©ãƒ•ã‚£ã‚¯ã‚¹ã¨CADåˆåŒã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼Œ2014-6ï¼
- æ¾¤ç”° å‹å“‰ï¼Œè±Šæµ¦ æ­£åºƒï¼ŒèŒ… æšé™½ï¼Œâ€œè¦–ç·šãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ˜ åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã®ã‚³ãƒŸãƒƒã‚¯ã®è‡ªå‹•ç”Ÿæˆâ€ï¼ŒVisual Computing/ã‚°ãƒ©ãƒ•ã‚£ã‚¯ã‚¹ã¨CADåˆåŒã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼Œ2014-6ï¼
- æ¾¤ç”° å‹å“‰ï¼Œè±Šæµ¦ æ­£åºƒï¼ŒèŒ… æšé™½ï¼Œâ€œè¦–ç·šæƒ…å ±ã‚’åˆ©ç”¨ã—ãŸæ˜ åƒã‹ã‚‰ã®ã‚³ãƒŸãƒƒã‚¯è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ â€ï¼Œã‚„ã¾ãªã—ç”£å­¦å®˜é€£æºç ”ç©¶äº¤æµäº‹æ¥­ï¼ŒArticle 17ï¼Œ2012-9
- æ¾¤ç”° å‹å“‰ï¼Œè±Šæµ¦ æ­£åºƒï¼ŒèŒ… æšé™½ï¼Œâ€œãƒ•ã‚£ãƒ«ãƒ ã‚³ãƒŸãƒƒã‚¯ã®è‡ªå‹•ç”Ÿæˆã«ãŠã‘ã‚‹è¦–ç·šæƒ…å ±ã®åˆ©ç”¨â€ï¼Œæƒ…å ±å‡¦ç†å­¦ä¼šå…¨å›½å¤§ä¼šï¼Œ1Q-9ï¼Œ2012-3


<!--
**kei-ts/kei-ts** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
